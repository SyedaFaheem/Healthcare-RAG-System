{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SyedaFaheem/Healthcare-RAG-System/blob/main/RAG_HealthCare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qf6TjtlWfdT1"
      },
      "source": [
        "# Healthcare RAG System Lab\n",
        "## Overview\n",
        "\n",
        "In this lab, you'll take on the role of a junior data scientist at a healthcare technology company that specializes in creating educational resources for patients. Your team has been tasked with developing a system that can automatically generate informative responses to common patient questions about medical conditions, treatments, and wellness practices.\n",
        "\n",
        "The challenge is to ensure these responses are both accurate and grounded in authoritative medical information. Your specific assignment is to implement a Retrieval-Augmented Generation (RAG) system that can:\n",
        "1. Understand patient questions about various health topics\n",
        "2. Retrieve relevant information from a trusted knowledge base\n",
        "3. Generate helpful, accurate responses based on that information\n",
        "4. Avoid \"hallucinated\" content that could potentially misinform patients\n",
        "\n",
        "This lab follows the generative AI implementation process we've studied, with particular focus on:\n",
        "- Data Strategy and Knowledge Foundation\n",
        "- Model Selection and Generation Control\n",
        "- Evaluation Framework Development\n",
        "\n",
        "## Setup\n",
        "\n",
        "First, let's import the necessary libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxROqw7ZfdT3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Check if CUDA is available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JXxaJItfdT4"
      },
      "source": [
        "## Part 1: Knowledge Base Setup\n",
        "\n",
        "Let's create a sample medical knowledge base with information about common health conditions, treatments, and wellness practices:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJA1xl-NfdT4"
      },
      "outputs": [],
      "source": [
        "# Create a sample medical knowledge base\n",
        "knowledge_base = pd.DataFrame({\n",
        "    'content': [\n",
        "        \"Diabetes is a chronic condition that affects how your body turns food into energy. There are three main types: Type 1, Type 2, and gestational diabetes. Type 2 diabetes is the most common form, accounting for about 90-95% of diabetes cases.\",\n",
        "        \"Type 1 diabetes is an autoimmune reaction that stops your body from making insulin. Symptoms include increased thirst, frequent urination, hunger, fatigue, and blurred vision. It's usually diagnosed in children, teens, and young adults.\",\n",
        "        \"Type 2 diabetes occurs when your body becomes resistant to insulin or doesn't make enough insulin. Risk factors include being overweight, being 45 years or older, having a parent or sibling with type 2 diabetes, and being physically active less than 3 times a week.\",\n",
        "        \"Managing diabetes involves monitoring blood sugar levels, taking medications as prescribed, eating a healthy diet, maintaining a healthy weight, and getting regular physical activity. It's important to work with healthcare providers to develop a management plan.\",\n",
        "        \"Hypertension, or high blood pressure, is when the force of blood pushing against the walls of your arteries is consistently too high. It's often called the 'silent killer' because it typically has no symptoms but significantly increases the risk of heart disease and stroke.\",\n",
        "        \"Blood pressure is measured using two numbers: systolic (top number) and diastolic (bottom number). Normal blood pressure is less than 120/80 mm Hg. Hypertension is diagnosed when readings are consistently 130/80 mm Hg or higher.\",\n",
        "        \"Lifestyle changes to manage hypertension include reducing sodium in your diet, getting regular physical activity, maintaining a healthy weight, limiting alcohol, quitting smoking, and managing stress. Medications may also be prescribed if lifestyle changes aren't enough.\",\n",
        "        \"Regular physical activity offers numerous health benefits, including weight management, reduced risk of heart disease, strengthened bones and muscles, improved mental health, and enhanced ability to perform daily activities. Adults should aim for at least 150 minutes of moderate-intensity activity per week.\",\n",
        "        \"A balanced diet should include a variety of fruits, vegetables, whole grains, lean proteins, and healthy fats. It's recommended to limit intake of added sugars, sodium, saturated fats, and processed foods. Proper nutrition helps prevent chronic diseases and supports overall health.\",\n",
        "        \"Vaccination is one of the most effective ways to prevent infectious diseases. Vaccines work by helping the body recognize and fight specific pathogens. Common adult vaccines include influenza (flu), Tdap (tetanus, diphtheria, pertussis), shingles, and pneumococcal vaccines.\"\n",
        "    ],\n",
        "    'metadata': [\n",
        "        {'topic': 'diabetes', 'subtopic': 'overview', 'source': 'medical_guidelines', 'last_updated': '2023-06-10'},\n",
        "        {'topic': 'diabetes', 'subtopic': 'type1', 'source': 'medical_guidelines', 'last_updated': '2023-06-10'},\n",
        "        {'topic': 'diabetes', 'subtopic': 'type2', 'source': 'medical_guidelines', 'last_updated': '2023-06-10'},\n",
        "        {'topic': 'diabetes', 'subtopic': 'management', 'source': 'medical_guidelines', 'last_updated': '2023-06-10'},\n",
        "        {'topic': 'hypertension', 'subtopic': 'overview', 'source': 'medical_guidelines', 'last_updated': '2023-07-22'},\n",
        "        {'topic': 'hypertension', 'subtopic': 'diagnosis', 'source': 'medical_guidelines', 'last_updated': '2023-07-22'},\n",
        "        {'topic': 'hypertension', 'subtopic': 'management', 'source': 'medical_guidelines', 'last_updated': '2023-07-22'},\n",
        "        {'topic': 'wellness', 'subtopic': 'physical_activity', 'source': 'health_promotion', 'last_updated': '2023-05-15'},\n",
        "        {'topic': 'wellness', 'subtopic': 'nutrition', 'source': 'health_promotion', 'last_updated': '2023-05-15'},\n",
        "        {'topic': 'prevention', 'subtopic': 'vaccination', 'source': 'medical_guidelines', 'last_updated': '2023-08-05'}\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(f\"Knowledge base loaded with {len(knowledge_base)} entries\")\n",
        "knowledge_base.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcoGWSWPfdT5"
      },
      "source": [
        "### Task 1: Create Document Embeddings\n",
        "\n",
        "Complete the function below to create embeddings for each document in the knowledge base. These embeddings will be used to find relevant documents based on patient queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8KCaKavfdT5"
      },
      "outputs": [],
      "source": [
        "def create_document_embeddings(documents):\n",
        "    \"\"\"\n",
        "    Create embeddings for a list of documents.\n",
        "\n",
        "    Args:\n",
        "        documents: List of text documents to embed\n",
        "\n",
        "    Returns:\n",
        "        Numpy array of document embeddings\n",
        "    \"\"\"\n",
        "    # Initialize a sentence transformer model\n",
        "    model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
        "    # Recommended: 'sentence-transformers/all-mpnet-base-v2' or similar\n",
        "    embedding_model ='sentence-transformers/all-mpnet-base-v2'\n",
        "\n",
        "    # Generate embeddings for all documents\n",
        "    # Hint: Use the model.encode() method\n",
        "    document_embeddings = model.encode(documents,show_progress_bar=True)\n",
        "\n",
        "    return document_embeddings\n",
        "\n",
        "# Extract document content\n",
        "documents = knowledge_base['content'].tolist()\n",
        "\n",
        "# Create document embeddings\n",
        "document_embeddings = create_document_embeddings(documents)\n",
        "\n",
        "# Verify the shape of embeddings\n",
        "if document_embeddings is not None:\n",
        "    print(f\"Generated embeddings with shape: {document_embeddings.shape}\")\n",
        "else:\n",
        "    print(\"Embeddings not created yet.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSPm6hkwfdT5"
      },
      "source": [
        "## Part 2: Implementing the Retrieval Component\n",
        "\n",
        "Now, let's implement the function to retrieve relevant documents based on a patient query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M07CdfmrfdT5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_documents(query, embeddings, contents, metadata, top_k=3, threshold=0.3):\n",
        "    \"\"\"\n",
        "    Retrieve the most relevant documents for a given query.\n",
        "\n",
        "    Args:\n",
        "        query: The patient's question (str)\n",
        "        embeddings: Precomputed document embeddings (numpy array)\n",
        "        contents: List of document texts\n",
        "        metadata: List of document metadata (dicts)\n",
        "        top_k: Maximum number of documents to retrieve\n",
        "        threshold: Minimum similarity score to include a document\n",
        "\n",
        "    Returns:\n",
        "        List of (content, metadata, similarity_score) tuples\n",
        "    \"\"\"\n",
        "    # Initialize the embedding model (same as used for documents)\n",
        "    model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
        "\n",
        "    # Embed the query\n",
        "    query_embedding = model.encode([query])  # shape (1, embedding_dim)\n",
        "\n",
        "    # Compute cosine similarity between query and all document embeddings\n",
        "    similarities = cosine_similarity(query_embedding, embeddings)[0]  # shape (num_docs,)\n",
        "\n",
        "    # Combine contents, metadata, and similarities\n",
        "    results = [\n",
        "        (contents[i], metadata[i], float(similarities[i]))\n",
        "        for i in range(len(contents))\n",
        "        if similarities[i] >= threshold\n",
        "    ]\n",
        "\n",
        "    # Sort by similarity descending and take top_k\n",
        "    results = sorted(results, key=lambda x: x[2], reverse=True)[:top_k]\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "F4QT_osVroRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxoagkMOfdT6"
      },
      "source": [
        "## Part 3: Building the Generation Component\n",
        "\n",
        "Now, let's implement the generation component that will use the retrieved documents to create informative responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhqSQxcqfdT6"
      },
      "outputs": [],
      "source": [
        "# Initialize the generative model\n",
        "def initialize_generator(model_name=\"gpt2\"):\n",
        "    \"\"\"\n",
        "    Initialize the generative model and tokenizer.\n",
        "\n",
        "    Args:\n",
        "        model_name: Name of the pretrained model to use\n",
        "\n",
        "    Returns:\n",
        "        Tokenizer and model objects\n",
        "    \"\"\"\n",
        "    # Load the tokenizer and model\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    # Replace with your code\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "    # Replace with your code\n",
        "\n",
        "    # Set padding token if needed\n",
        "    # Check if pad_token exists, if not set it to eos_token\n",
        "    if tokenizer.pad_token is None:\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "    return tokenizer, model\n",
        "\n",
        "# Initialize the generator\n",
        "tokenizer, model = initialize_generator()\n",
        "if tokenizer and model:\n",
        "    print(f\"Initialized {model.config._name_or_path} with {model.num_parameters()} parameters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcqG7abBfdT6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_rag_response(query, contents, metadata, document_embeddings, tokenizer, model, max_length=150, top_k=5, threshold=0.2):\n",
        "    \"\"\"\n",
        "    Generate a response using Retrieval-Augmented Generation (RAG).\n",
        "\n",
        "    Args:\n",
        "        query: The patient's question\n",
        "        contents: List of document contents\n",
        "        metadata: List of document metadata\n",
        "        document_embeddings: Precomputed embeddings for the documents\n",
        "        tokenizer: Tokenizer for the language model\n",
        "        model: The language model for generation\n",
        "        max_length: Maximum response length\n",
        "        top_k: Number of top documents to retrieve\n",
        "        threshold: Minimum similarity for documents to include\n",
        "\n",
        "    Returns:\n",
        "        dict: Generated response and retrieved documents\n",
        "    \"\"\"\n",
        "    # --- 1. Retrieve relevant documents ---\n",
        "    retrieved_docs = retrieve_documents(\n",
        "        query=query,\n",
        "        embeddings=document_embeddings,\n",
        "        contents=contents,\n",
        "        metadata=metadata,\n",
        "        top_k=top_k,\n",
        "        threshold=threshold\n",
        "    )\n",
        "\n",
        "    # --- 2. Format the prompt ---\n",
        "    if retrieved_docs:\n",
        "        context_texts = [f\"Document {i+1}: {doc[0]}\" for i, doc in enumerate(retrieved_docs)]\n",
        "        context_str = \"\\n\".join(context_texts)\n",
        "        prompt = f\"Answer the following question based on the context below:\\n{context_str}\\n\\nQuestion: {query}\\nAnswer:\"\n",
        "    else:\n",
        "        prompt = f\"Answer the following question:\\n{query}\\nAnswer:\"\n",
        "\n",
        "    # --- 3. Tokenize the prompt ---\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    # --- 4. Generate the response ---\n",
        "    with torch.no_grad():\n",
        "        output_sequences = model.generate(\n",
        "            input_ids=inputs[\"input_ids\"],\n",
        "            attention_mask=inputs[\"attention_mask\"],\n",
        "            max_length=max_length,\n",
        "            temperature=0.7,\n",
        "            top_k=50,\n",
        "            top_p=0.9,\n",
        "            do_sample=True,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "            pad_token_id=tokenizer.pad_token_id\n",
        "        )\n",
        "\n",
        "    # --- 5. Decode the generated text ---\n",
        "    response = tokenizer.decode(output_sequences[0], skip_special_tokens=True)\n",
        "\n",
        "    # Optional: remove the prompt from the output to get only the answer\n",
        "    response = response.replace(prompt, \"\").strip()\n",
        "\n",
        "    return {\n",
        "        \"query\": query,\n",
        "        \"response\": response,\n",
        "        \"retrieved_documents\": retrieved_docs\n",
        "    }"
      ],
      "metadata": {
        "id": "6wLhrSfOuiv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAqx1pfpfdT7"
      },
      "source": [
        "## Part 4: Evaluation and Analysis\n",
        "\n",
        "Let's implement a basic evaluation function to assess the quality of our generated responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dvzAOkVfdT7"
      },
      "outputs": [],
      "source": [
        "def evaluate_response(response_data):\n",
        "    \"\"\"\n",
        "    Evaluate the quality of a generated response based on various criteria.\n",
        "\n",
        "    Args:\n",
        "        response_data: Dictionary containing the query, response, and retrieved docs\n",
        "\n",
        "    Returns:\n",
        "        dict: Evaluation metrics\n",
        "    \"\"\"\n",
        "    response_text = response_data.get(\"response\", \"\").lower()\n",
        "    retrieved_docs = response_data.get(\"retrieved_documents\", [])\n",
        "\n",
        "    # --- Metric 1: Content Relevance ---\n",
        "    # Count how many unique words from retrieved documents appear in the response\n",
        "    doc_terms = set()\n",
        "    for doc, _, _ in retrieved_docs:\n",
        "        words = re.findall(r'\\b\\w+\\b', doc.lower())\n",
        "        doc_terms.update(words)\n",
        "\n",
        "    if doc_terms:\n",
        "        matched_terms = [term for term in doc_terms if term in response_text]\n",
        "        content_relevance = len(matched_terms) / len(doc_terms)\n",
        "    else:\n",
        "        content_relevance = 0.0\n",
        "\n",
        "    # --- Metric 2: Medical Terminology Usage ---\n",
        "    medical_terms = [\n",
        "        \"diabetes\", \"insulin\", \"glucose\", \"hypertension\", \"blood pressure\",\n",
        "        \"systolic\", \"diastolic\", \"cardiovascular\", \"cholesterol\", \"nutrition\",\n",
        "        \"obesity\", \"physical activity\", \"vaccination\", \"immune\", \"prevention\"\n",
        "    ]\n",
        "    medical_matches = [term for term in medical_terms if term in response_text]\n",
        "    medical_term_score = len(medical_matches) / len(medical_terms)\n",
        "\n",
        "    # --- Metric 3 (optional): Response Length Appropriateness ---\n",
        "    # Simple heuristic: check if response length is between 50 and 300 characters\n",
        "    length_score = 1.0 if 50 <= len(response_text) <= 300 else 0.5 if len(response_text) < 50 else 0.8\n",
        "\n",
        "    # Combine metrics\n",
        "    metrics = {\n",
        "        \"content_relevance\": round(content_relevance, 3),\n",
        "        \"medical_term_usage\": round(medical_term_score, 3),\n",
        "        \"length_score\": round(length_score, 3),\n",
        "        \"num_medical_terms_mentioned\": len(medical_matches)\n",
        "    }\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrY-TPgnfdT7"
      },
      "source": [
        "## Reflection Questions\n",
        "\n",
        "Answer the following questions about your RAG implementation and its potential applications in healthcare:\n",
        "\n",
        "### How does the RAG approach improve factual accuracy compared to regular generation?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYnkxDf2fdT7"
      },
      "source": [
        "By grounding the model’s responses in actual documents from a curated knowledge base. Instead of relying solely on the language model’s learned patterns , RAG first retrieves relevant documents and then generates answers conditioned on that content. This reduces misinformation and increases reliability, especially for healthcare topics where factual correctness is critical."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7KTkoINfdT7"
      },
      "source": [
        "### What are potential challenges or limitations of your current implementation?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtkswNg7fdT7"
      },
      "source": [
        "- If embeddings or the similarity threshold are suboptimal, irrelevant documents may be retrieved, reducing answer accuracy.\n",
        "\n",
        "- The current implementation compares the query against all embeddings linearly, which can become slow for thousands of documents.\n",
        "\n",
        "- GPT-style models have a maximum token length, so long contexts or multiple retrieved documents may exceed the limit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1-OVG2yfdT7"
      },
      "source": [
        "### How might you enhance this system for a production healthcare environment?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfR4ZGsCfdT7"
      },
      "source": [
        "- Vector database integration: Use FAISS, Milvus, or Pinecone to efficiently scale retrieval to thousands of documents.\n",
        "\n",
        "- Domain-specific models: Fine-tune embeddings and the generative model on medical corpora (e.g., PubMed, clinical guidelines).\n",
        "\n",
        "- Context filtering and summarization: Summarize retrieved documents before feeding them to the generator to stay within token limits.\n",
        "\n",
        "- Human-in-the-loop validation: Include clinician review or fact-checking to verify responses.\n",
        "\n",
        "- Logging and auditing: Track query-response pairs for traceability and continuous model improvement.\n",
        "\n",
        "- Security & privacy: Ensure patient data is handled in compliance with HIPAA or GDPR."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLDdJQWXfdT7"
      },
      "source": [
        "### What ethical considerations are particularly important for healthcare content generation?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-i_dSZQfdT7"
      },
      "source": [
        "- Accuracy and reliability: Responses must be factually correct; misinformation could harm patients.\n",
        "\n",
        "- Patient privacy: Never expose personally identifiable information or medical records.\n",
        "\n",
        "- Bias mitigation: Ensure the model does not reinforce health disparities or provide unsafe recommendations.\n",
        "\n",
        "- Transparency: Clearly indicate that responses are AI-generated and may require professional verification.\n",
        "\n",
        "- Responsibility: Healthcare AI should supplement, not replace, professional medical advice."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Cohort_Env)",
      "language": "python",
      "name": "cohort_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}